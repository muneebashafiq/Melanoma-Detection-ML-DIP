# -*- coding: utf-8 -*-
"""DIP_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DCM2eXJH624LEpotV-BZhgWfpyUtuP84
"""

# mount google drive

from google.colab import drive
drive.mount('/content/drive')

# import necessary libraries for DIP

import os
import cv2
import numpy as np
from zipfile import ZipFile
import csv
import pandas as pd
from tqdm import tqdm
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# dataset site url

dataset_url = "https://www.dropbox.com/s/k88qukc20ljnbuo/PH2Dataset.rar?e=2&file_subpath=%2FPH2Dataset"

# path to store dataset

drive_dir = "/content/drive/MyDrive"

# Commented out IPython magic to ensure Python compatibility.

# Change directory to the destination directory

# %cd $drive_dir

# Download the dataset file to the destination directory in Google Drive

!wget $dataset_url

# Unrar the dataset file (assuming it's in RAR format)

!apt-get install unrar
!unrar x "PH2Dataset.rar?e=2"

# save paths of dermoscopic images in csv file

# Define the path to the directory containing the dataset
dataset_dir = "/content/drive/MyDrive/PH2Dataset/PH2 Dataset images"

# Function to load dermoscopic images and save their paths to a CSV file
def load_dermoscopic_images(dataset_dir, csv_file):
    # Initialize a list to store the image paths
    image_paths = []

    # Iterate over the subfolders in the dataset directory
    for image_folder in os.listdir(dataset_dir):
        # Construct the full path to the image folder
        full_image_folder = os.path.join(dataset_dir, image_folder)
        # Check if the item in the dataset directory is a directory
        if os.path.isdir(full_image_folder):
            try:
                # Define the path to the dermoscopic image folder
                dermoscopic_image_folder = os.path.join(full_image_folder, f"{image_folder}_Dermoscopic_Image")
                # Check if the dermoscopic image folder exists
                if os.path.isdir(dermoscopic_image_folder):
                    # Define the path to the dermoscopic image file
                    dermoscopic_image_path = os.path.join(dermoscopic_image_folder, f"{image_folder}.bmp")
                    # Append the image path and ID to the list
                    image_paths.append((image_folder, dermoscopic_image_path))
                else:
                    raise FileNotFoundError(f"Dermoscopic image folder not found for: {image_folder}")
            except Exception as e:
                print(f"Error processing {image_folder}: {e}")

    # Write the image paths to the CSV file
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['ID', 'Image Path'])
        writer.writerows(image_paths)

    return image_paths

# Define the path to the CSV file
csv_file_path = "/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv"

# Load dermoscopic images and save their paths to the CSV file
image_paths = load_dermoscopic_images(dataset_dir, csv_file_path)

# Display the first few image paths
print("Saved dermoscopic image paths to:", csv_file_path)
print("Sample image paths:")
for id, path in image_paths[:5]:
    print(f"ID: {id}, Path: {path}")

# RESIZE IMAGAES

# Load the CSV file containing image paths
csv_file_path = '/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv'
df = pd.read_csv(csv_file_path)

# Define the target size for resizing
target_size = (767, 576)  # Example size, choose according to your requirements

# Create a list to store resized images
resized_images = []

# Iterate through each row in the DataFrame
for index, row in tqdm(df.iterrows(), total=len(df), desc="Resizing Images"):
    # Read the image path from the current row
  image_path = row['Image Path']

    # Load the image using OpenCV
  image = cv2.imread(image_path)

    # Resize the image
  resized_image = cv2.resize(image, target_size)

    # Append the resized image to the list
  resized_images.append(resized_image)

# ADJUST BRIGHTNESS/CONTRAST

# Create a list to store adjusted images
adjusted_images = []

# Define the alpha (contrast) and beta (brightness) values
alpha = 1.2  # Contrast control (1.0-3.0)
beta = 9  # Brightness control (0-100)

# Iterate through each image in the list of resized images
for image in resized_images:
  # Apply brightness and contrast adjustment
  adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)

  # Append the adjusted image to the list
  adjusted_images.append(adjusted_image)

# Display the first 10 adjusted images
index=[118,0,8,22,5]
for i in index:
    if i < len(adjusted_images):
        cv2_imshow(resized_images[i])
        cv2_imshow(adjusted_images[i])
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    else:
        print(f"No adjusted image available at index {i}")

#NOISE REMOVING FILTERS

    # remove hair and noise

def remove_hairs_and_noise(adjusted_images):
    # Load the dermoscopic image
  image = adjusted_images

    # Convert the image to grayscale
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur to reduce noise
  blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Apply adaptive thresholding to segment darker regions (hairs and noise)
  thresholded = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)

    # Perform morphological closing to fill small holes and gaps in the foreground
  kernel = np.ones((5, 5), np.uint8)
  closing = cv2.morphologyEx(thresholded, cv2.MORPH_CLOSE, kernel)

    # Inpaint the detected regions to remove hairs and noise
  inpainted = cv2.inpaint(image, closing, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

  return inpainted


# List to store processed images
processed_images = []

# Process each dermoscopic image to remove hairs and noise
for image_path in tqdm(adjusted_images, desc='Processing images'):
  processed_image = remove_hairs_and_noise(image_path)
  processed_images.append(processed_image)

# Now you have all processed images stored in the 'processed_images' list
# You can use this list for further processing or analysis

import pandas as pd

# Load the CSV file containing image paths and IDs
csv_file_path = "/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv"
data = pd.read_csv(csv_file_path)

# Extract image IDs from the CSV file
image_ids = data["ID"]

# Convert image IDs to a list
image_ids_list = image_ids.tolist()

# Display the extracted image IDs
print("Image IDs:", image_ids_list)

import os

# Create a directory to save the processed images
output_directory = "/content/drive/MyDrive/PH2Dataset/noisless_images"
os.makedirs(output_directory, exist_ok=True)

# Iterate through the processed images and save them with their IDs
for img_id, processed_image in zip(image_ids_list, processed_images):
    img_name = f"{img_id}.bmp"
    img_path = os.path.join(output_directory, img_name)
    cv2.imwrite(img_path, processed_image)

# Display the first 5 adjusted images
for i in range(5):
    if i < len(adjusted_images):
        cv2_imshow(adjusted_images[i])
        cv2_imshow(processed_images[i])
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    else:
        print(f"No adjusted image available at index {i}")

import os
import csv
import cv2
processed_images=[]
# Function to read sequence from CSV file
def read_sequence_from_csv(csv_file):
    sequence = []
    with open(csv_file, 'r') as file:
        reader = csv.reader(file)
        for row in reader:
            sequence.append(row[0] + '.bmp')  # Add the file extension
    return sequence

# Function to load images and store in a list
def load_images_from_folder(folder, sequence):
    images = []
    for filename in sequence:
        img_path = os.path.join(folder, filename)
        if os.path.exists(img_path):  # Check if the image file exists
            img = cv2.imread(img_path)
            images.append(img)
        else:
            print(f"Image not found: {img_path}")
    return images

# Folder containing images
folder_path = '/content/drive/MyDrive/PH2Dataset/noisless_images/'

# CSV file containing sequence of image filenames
csv_file_path = '/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv'

# Read sequence from CSV file
sequence = read_sequence_from_csv(csv_file_path)

# Load images and store in a list
processed_images = load_images_from_folder(folder_path, sequence)

# Check the number of images loaded
print(f"Number of images loaded: {len(processed_images)}")

# Define the alpha (contrast) and beta (brightness) values
alpha = 1  # Contrast control (1.0-3.0)
beta = -20  # Brightness control (0-100)

# Create a list to store contrast-enhanced images
enhanced_images = []
# Apply contrast enhancement to each image in the list of processed images
for image in tqdm(processed_images, desc='Enhancing contrast'):
    # Apply contrast enhancement
    enhanced_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
    # Append the enhanced image to the list
    enhanced_images.append(enhanced_image)

# Now you have all contrast-enhanced images stored in the 'enhanced_images' list
# You can use this list for further processing or analysis

for i in range(30):
        cv2_imshow(processed_images[i])
        cv2_imshow(enhanced_images[i])
        cv2.waitKey(0)
        cv2.destroyAllWindows()

import cv2

def color_normalization(image):
    # Convert the image to LAB color space
    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)

    # Split the LAB image into channels
    l_channel, a_channel, b_channel = cv2.split(lab_image)

    # Apply histogram equalization to the L channel with contrast limited adaptive histogram equalization (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_channel_equalized = clahe.apply(l_channel)

    # Merge the equalized L channel with the original A and B channels
    normalized_lab_image = cv2.merge((l_channel_equalized, a_channel, b_channel))

    # Convert the normalized LAB image back to BGR color space
    normalized_image = cv2.cvtColor(normalized_lab_image, cv2.COLOR_LAB2BGR)

    return normalized_image

# Create a list to store normalized images
normalized_images = []

# Iterate through each image in the list of hair removed images
for image in enhanced_images:  # Assuming hair_removed_images is your list of images
    # Apply color normalization
    normalized_image = color_normalization(image)
    # Append the normalized image to the list
    normalized_images.append(normalized_image)

# Display the original and normalized images for the first image in the list
cv2_imshow(enhanced_images[0])
cv2_imshow(normalized_images[0])
cv2.waitKey(0)
cv2.destroyAllWindows()

# Define the alpha (contrast) and beta (brightness) values
alpha = 1  # Contrast control (1.0-3.0)
beta = -20  # Brightness control (0-100)

# Create a list to store contrast-enhanced images
high_enhanced_images = []
# Apply contrast enhancement to each image in the list of processed images
for image in tqdm(normalized_images, desc='Enhancing contrast'):
    # Apply contrast enhancement
    enhanced_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
    # Append the enhanced image to the list
    high_enhanced_images.append(enhanced_image)

# Now you have all contrast-enhanced images stored in the 'enhanced_images' list
# You can use this list for further processing or analysis

m=[112,131,133,141,160]
for i in m:
        cv2_imshow(high_enhanced_images[i])
        cv2_imshow(normalized_images[i])
        cv2.waitKey(0)
        cv2.destroyAllWindows()

m=[112,131,133,141,160]
for i in m:
        cv2_imshow(high_enhanced_images[i])
        cv2_imshow(lesion_mask[i])
        cv2.waitKey(0)
        cv2.destroyAllWindows()

def extract_lesion_mask(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Use adaptive thresholding to segment the lesion
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Perform morphological operations to enhance the mask
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    sure_bg = cv2.dilate(opening, kernel, iterations=10)

    # Find contours in the mask
    contours, _ = cv2.findContours(sure_bg.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create an empty mask for the lesion
    lesion_mask = np.zeros_like(gray)

    # Draw contours on the lesion mask
    for contour in contours:
        cv2.drawContours(lesion_mask, [contour], -1, 255, -1)

    return lesion_mask

# Create a list to store lesion masks
lesion_masks_list = []

# Iterate through each image in the list of processed images
for image in high_enhanced_images:
    # Extract the lesion mask and append it to the list
    lesion_mask = extract_lesion_mask(image)
    lesion_masks_list.append(lesion_mask)

# Display the lesion masks for the first 10 images
for i in range(10):
    cv2_imshow(lesion_masks_list[i])
    cv2.waitKey(0)
    cv2.destroyAllWindows()

import cv2
import numpy as np

# Function to apply mask to the original image
def apply_mask_to_image(image, mask):
    # Threshold the mask to obtain binary mask
    _, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)

    # Find contours
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create a mask of zeros with the same shape as the input image
    final_mask = np.zeros_like(image)

    if contours:
        # Find the largest contour
        largest_contour = max(contours, key=cv2.contourArea)

        # Draw the largest contour on the mask
        cv2.drawContours(final_mask, [largest_contour], 0, (255), thickness=cv2.FILLED)

    # Apply the mask to the original image
    result = cv2.bitwise_and(image, final_mask)

    return result

# List to store results
masked_images = []

# Apply the code to each lesion mask
for lesion_mask in lesion_masks_list:
    # Apply mask to the original image
    masked_image = apply_mask_to_image(lesion_mask, lesion_mask)

    # Append the masked image to the list
    masked_images.append(masked_image)

# Display the masked images
jm=[112,131,133,141,160]
for i in jm:
    cv2_imshow(normalized_images[i])
    cv2_imshow(masked_images[i])
    cv2.waitKey(0)
    cv2.destroyAllWindows()

print(len(masked_images))

import pandas as pd
import cv2

def apply_mask_to_image(original_image, mask):
    # Apply the mask to the original image
    result = cv2.bitwise_and(original_image, original_image, mask=mask)

    return result

# Create a list to store the masked images
masked_imagess = []

# Iterate through each pair of original image and lesion mask
for original_image, lesion_mask in zip(high_enhanced_images, masked_images):
    # Apply the mask to the original image
    masked_image = apply_mask_to_image(original_image, lesion_mask)

    # Append the masked image to the list
    masked_imagess.append(masked_image)

# Display the masked images for the first 10 images
for i in range(2):
    cv2_imshow(high_enhanced_images[i])
    cv2_imshow(masked_imagess[i])
    cv2.waitKey(0)
    cv2.destroyAllWindows()

import os

# Create a directory to save the processed images
output_directory = "/content/drive/MyDrive/PH2Dataset/masked_images"
os.makedirs(output_directory, exist_ok=True)

# Iterate through the processed images and save them with their IDs
for img_id, masked_imagess in zip(image_ids_list, masked_imagess):
    img_name = f"{img_id}.bmp"
    img_path = os.path.join(output_directory, img_name)
    cv2.imwrite(img_path, masked_imagess)

import cv2
import numpy as np
import pandas as pd
import skimage.feature
from skimage.color import rgb2lab
from skimage.measure import shannon_entropy

def extract_texture_features(image):
    # Convert image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

    # Convert to unsigned integer type
    gray_image_uint = (gray_image * 255).astype(np.uint8)

    # Compute GLCM
    distances = [1, 2, 3]
    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]
    glcm = skimage.feature.graycomatrix(gray_image_uint, distances, angles, symmetric=True, normed=True)

    # Compute GLCM properties
    contrast = skimage.feature.graycoprops(glcm, 'contrast').ravel()
    dissimilarity = skimage.feature.graycoprops(glcm, 'dissimilarity').ravel()
    homogeneity = skimage.feature.graycoprops(glcm, 'homogeneity').ravel()
    energy = skimage.feature.graycoprops(glcm, 'energy').ravel()
    correlation = skimage.feature.graycoprops(glcm, 'correlation').ravel()

    return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

def extract_color_features(image):
    # Convert image to Lab color space
    lab_image = rgb2lab(image)

    # Compute mean and standard deviation for each channel
    mean_lab = np.mean(lab_image, axis=(0, 1))
    std_lab = np.std(lab_image, axis=(0, 1))

    return np.concatenate([mean_lab, std_lab])

def extract_shape_features(image):
    # Compute Shannon entropy as a shape feature
    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    entropy = shannon_entropy(gray_image)

    # Compute area and perimeter as additional shape features
    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    area = cv2.contourArea(contours[0])
    perimeter = cv2.arcLength(contours[0], closed=True)

    return np.array([entropy, area, perimeter])

def extract_features_from_images(images, image_ids):
    all_features = []

    for image, image_id in zip(images, image_ids):
        texture_feats = extract_texture_features(image)
        color_feats = extract_color_features(image)
        shape_feats = extract_shape_features(image)

        features = np.concatenate([texture_feats, color_feats, shape_feats])
        all_features.append(features)

    return np.array(all_features)

import pandas as pd

# Load image paths and IDs from the CSV file
image_data = pd.read_csv('/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv')

# Extract only the IDs
image_ids = image_data['ID'].tolist()
images=masked_imagess
# Assuming you already have the images stored in a list called 'images'

# Now you can proceed to extract features from the images using the 'images' list and 'image_ids'
# Replace the placeholder 'images' with your actual list of images in the following code snippet

# Extract features from images
all_features = extract_features_from_images(images, image_ids)

# Create a DataFrame to store features along with image IDs
texture_feature_names = [f'texture_feature_{i}' for i in range(60)]
color_feature_names = [f'color_feature_{i}' for i in range(6)]
shape_feature_names = ['shape_entropy', 'shape_area', 'shape_perimeter']
feature_names = texture_feature_names + color_feature_names + shape_feature_names
df = pd.DataFrame(all_features, columns=feature_names)
df['Image_ID'] = image_ids

# Save the DataFrame to a CSV file
# df.to_csv('/content/drive/MyDrive/PH2Dataset/image_featuresss.csv', index=False)

import pandas as pd

# Load image features from existing CSV file
image_features_df = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_featuresss.csv')

# Load labels (levels) from Excel file
labels_df = pd.read_excel('/content/drive/MyDrive/Label.xlsx')

# Rename the column in labels_df to match the column name in image_features_df
labels_df.rename(columns={'Image': 'Image_ID'}, inplace=True)

# Check column names in both DataFrames
print("Columns in image_features_df:", image_features_df.columns)
print("Columns in labels_df:", labels_df.columns)

# Ensure that the column names are the same
if 'Image_ID' not in image_features_df.columns or 'Image_ID' not in labels_df.columns:
    raise KeyError("Column 'Image_ID' not found in both DataFrames.")

# Merge datasets based on image IDs
merged_df = pd.merge(image_features_df, labels_df, on='Image_ID', how='left')

# Save the updated dataset to a new CSV file
merged_df.to_csv('/content/drive/MyDrive/PH2Dataset/image_features_with_levelss.csv', index=False)

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_features_with_levelss.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a Support Vector Machine (SVM) classifier
svm_clf = SVC(kernel='linear')
svm_clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = svm_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Calculate AUC
y_scores = svm_clf.decision_function(X_test)
auc = roc_auc_score(y_test, y_scores)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)
print("AUC:", auc)

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_features_with_levelss.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a k-Nearest Neighbors (KNN) classifier
knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = knn_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)

# Note: KNN does not directly provide decision_function() method for AUC calculation

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_features_with_levelss.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a logistic regression classifier
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = log_reg.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)

# Calculate ROC AUC score
y_pred_proba = log_reg.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)
print("ROC AUC Score:", auc)

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_features_with_levelss.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a decision tree classifier
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = decision_tree.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)



# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

import skimage.feature
from skimage.measure import regionprops
from skimage.measure import shannon_entropy

# Function to extract texture features using GLCM (Grey Level Co-occurrence Matrix)
def extract_texture_features(image):
    # Convert image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Compute GLCM
    glcm = skimage.graycomatrix(gray_image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)
    # Extract texture features
    contrast = skimage.feature.graycoprops(glcm, 'contrast')
    dissimilarity = skimage.feature.graycoprops(glcm, 'dissimilarity')
    homogeneity = skimage.feature.graycoprops(glcm, 'homogeneity')
    energy = skimage.feature.graycoprops(glcm, 'energy')
    correlation = skimage.feature.graycoprops(glcm, 'correlation')

    return contrast[0, 0], dissimilarity[0, 0], homogeneity[0, 0], energy[0, 0], correlation[0, 0]

# Function to extract shape features
def extract_shape_features(image):
    # Compute Shannon entropy as a shape feature
    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    entropy = shannon_entropy(gray_image)

    # Compute area and perimeter as additional shape features
    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    area = cv2.contourArea(contours[0])
    perimeter = cv2.arcLength(contours[0], closed=True)

    return entropy, area, perimeter

# Function to extract color features
def extract_color_features(image):
    # Convert image to HSV color space
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    # Calculate mean color
    mean_color = cv2.mean(hsv_image)[:3]

    return mean_color

def extract_hybrid_features_from_images(images, image_ids):
    all_features = []

    for image, image_id in zip(images, image_ids):
        texture_feats = extract_texture_features(image)
        color_feats = extract_color_features(image)
        shape_feats = extract_shape_features(image)

        features = np.concatenate([texture_feats, color_feats, shape_feats])
        all_features.append(features)

    return np.array(all_features)

# Load image paths and IDs from the CSV file
image_data = pd.read_csv('/content/drive/MyDrive/PH2Dataset/dermoscopic_image_paths.csv')

# Extract only the IDs
image_ids = image_data['ID'].tolist()
images=masked_imagess

# Extract features from images
all_features = extract_hybrid_features_from_images(images, image_ids)

# Create a DataFrame to store features along with image IDs
texture_feature_names = ['Contrast', 'Dissimilarity', 'Homogeneity', 'Energy', 'Correlation']
color_feature_names = ['Mean_Hue', 'Mean_Saturation', 'Mean_Value']
shape_feature_names = ['Area', 'Perimeter', 'Entropy']
feature_names = texture_feature_names + color_feature_names + shape_feature_names
df = pd.DataFrame(all_features, columns=feature_names)
df['Image_ID'] = image_ids

# Save the DataFrame to a CSV file
df.to_csv('/content/drive/MyDrive/PH2Dataset/image_featuresss4.csv', index=False)

import pandas as pd

# Load image features from existing CSV file
image_features_df = pd.read_csv('/content/drive/MyDrive/PH2Dataset/image_featuresss4.csv')

# Load labels (levels) from Excel file
labels_df = pd.read_excel('/content/drive/MyDrive/Label.xlsx')

# Rename the column in labels_df to match the column name in image_features_df
labels_df.rename(columns={'Image': 'Image_ID'}, inplace=True)

# Check column names in both DataFrames
print("Columns in image_features_df:", image_features_df.columns)
print("Columns in labels_df:", labels_df.columns)

# Ensure that the column names are the same
if 'Image_ID' not in image_features_df.columns or 'Image_ID' not in labels_df.columns:
    raise KeyError("Column 'Image_ID' not found in both DataFrames.")

# Merge datasets based on image IDs
merged_df = pd.merge(image_features_df, labels_df, on='Image_ID', how='left')

# Save the updated dataset to a new CSV file
merged_df.to_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv', index=False)

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a Support Vector Machine (SVM) classifier
svm_clf = SVC(kernel='linear')
svm_clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = svm_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Calculate AUC
y_scores = svm_clf.decision_function(X_test)
auc = roc_auc_score(y_test, y_scores)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)
print("AUC:", auc)

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

import seaborn as sns
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('SVM Confusion Matrix')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a k-Nearest Neighbors (KNN) classifier
knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = knn_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)

# Note: KNN does not directly provide decision_function() method for AUC calculation

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

plt.figure(figsize=(8, 6))
knn_ = confusion_matrix(y_test, y_pred)
sns.heatmap(knn_, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('KNN Confusion Matrix')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a logistic regression classifier
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = log_reg.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)

# Calculate ROC AUC score
y_pred_proba = log_reg.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)
print("ROC AUC Score:", auc)

# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

plt.figure(figsize=(8, 6))
lr_ = confusion_matrix(y_test, y_pred)
sns.heatmap(lr_, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Logistic Regression Confusion Matrix')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix
import pandas as pd

# Load the dataset
dataset = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv')

# Separate features and labels
X = dataset.drop(['Image_ID', 'Label'], axis=1)
y = dataset['Label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train a decision tree classifier
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = decision_tree.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Calculate sensitivity, specificity, precision
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("Sensitivity:", sensitivity)
print("Specificity:", specificity)
print("Precision:", precision)
print("Recall:", recall)


# Display the actual and predicted classes for the testing data
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
results_with_names_df = pd.merge(results_df, dataset[['Image_ID']], left_index=True, right_index=True)
print(results_with_names_df)

import seaborn as sns
plt.figure(figsize=(8, 6))
dt = confusion_matrix(y_test, y_pred)
sns.heatmap(dt, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Decision Tree Confusion Matrix')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the CSV file into a DataFrame
df = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss.csv')

# Extract 'Image_ID' and 'Label' columns
image_ids = df['Image_ID'][135:165]
labels = df['Label'][135:165]

# Plotting image_id (name) and label
plt.figure(figsize=(10, 6))
plt.bar(image_ids, labels, color='skyblue')
plt.xlabel('Image ID')
plt.ylabel('Label')
plt.title('Image ID vs Label')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

# Load the CSV file into a DataFrame
df = pd.read_csv('/content/drive/MyDrive/PH2Dataset/updated_image_features_with_levelss3.csv')

# Assuming 'features' contains the features and 'labels' contains the target labels
X = df.drop(columns=['Label','Image_ID'])  # Features
y = df['Label']  # Target labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize classifiers
classifiers = {
    'SVM': SVC(),
    'KNN': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(),
    'Logistic Regression': LogisticRegression()
}

# Train and evaluate each classifier
accuracies = {}
for clf_name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracies[clf_name] = accuracy_score(y_test, y_pred)

# Plot the accuracies
plt.figure(figsize=(10, 6))
plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
plt.ylim(0, 1)
plt.show()